{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#### **Module 2: Neural Network Building Blocks**\n",
        "\n",
        "\n",
        "\n",
        "Neural Network\n",
        "\n",
        "<img src = 'https://learnopencv.com/wp-content/uploads/2017/10/mlp-diagram.jpg' height=300 width=600>\n",
        "\n",
        "Node/Neuron/Perceptron\n",
        "\n",
        "<img src='https://media.geeksforgeeks.org/wp-content/uploads/20250528125143444422/Activation-functions-in-Neural-Networks.webp' height=300 width=600>\n",
        "\n",
        "\n",
        "**Activation function**\n",
        "\n",
        "In a neural network, an activation function determines the output of a neuron based on its input. It introduces non-linearity, allowing the network to learn complex patterns, and decides whether a neuron should be activated or not, passing a signal to the next layer.\n",
        "\n",
        "<img src= 'https://www.researchgate.net/publication/344331692/figure/fig8/AS:965939822616576@1607309408063/Artificial-neural-network-activation-functions-In-this-figure-the-most-common.ppm' height=200 width=600>"
      ],
      "metadata": {
        "id": "fC3-v7DDccwj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z2ntqQrwcVQz"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Data Preparation"
      ],
      "metadata": {
        "id": "RT6diJtFkcGN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "N_SAMPLES_PER_CLASS = 500\n",
        "N_FEATURES = 2\n",
        "RANDOM_SEED = 42\n",
        "torch.manual_seed(RANDOM_SEED)\n",
        "\n",
        "class0_points = torch.randn(N_SAMPLES_PER_CLASS, N_FEATURES) + torch.tensor([-2, -2])\n",
        "class0_labels = torch.zeros(N_SAMPLES_PER_CLASS, 1)\n",
        "\n",
        "\n",
        "\n",
        "class1_points = torch.randn(N_SAMPLES_PER_CLASS, N_FEATURES) + torch.tensor([2, 2])\n",
        "class1_labels = torch.ones(N_SAMPLES_PER_CLASS, 1)\n",
        "\n",
        "X = torch.cat([class0_points, class1_points], dim=0)\n",
        "y = torch.cat([class0_labels, class1_labels], dim=0)\n",
        "\n",
        "print(X)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nR0syeLljRY7",
        "outputId": "8e7a84fa-c342-44d3-d3df-237481915e06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.0731, -0.5127],\n",
            "        [-1.0993, -4.1055],\n",
            "        [-1.3216, -3.2345],\n",
            "        ...,\n",
            "        [ 2.4603,  3.1791],\n",
            "        [ 0.9894,  1.3797],\n",
            "        [ 0.5451,  1.4102]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y.unique(), len(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u-Ifvcdc_6lk",
        "outputId": "b6f291fc-c16b-410d-a57f-ae0fc5f711f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([0., 1.]), 1000)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "shuffled_indices = torch.randperm(len(X))\n",
        "# shuffled_indices"
      ],
      "metadata": {
        "id": "FgNc6LLcAtcl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the split point (e.g., 80% for training, 20% for testing)\n",
        "train_size = int(0.8 * len(X))\n",
        "train_indices = shuffled_indices[:train_size]\n",
        "test_indices = shuffled_indices[train_size:]\n",
        "\n",
        "\n",
        "# Create the training and testing sets using the indices\n",
        "X_train, y_train = X[train_indices], y[train_indices]\n",
        "X_test, y_test = X[test_indices], y[test_indices]\n",
        "\n",
        "print(f\"Total samples: {len(X)}\")\n",
        "print(f\"Training samples: {len(X_train)}\")\n",
        "print(f\"Testing samples: {len(X_test)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k3A00twlAUB3",
        "outputId": "3f2743b1-fc96-417d-bd26-cc449e0a9278"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total samples: 1000\n",
            "Training samples: 800\n",
            "Testing samples: 200\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Dataset and DataLoader"
      ],
      "metadata": {
        "id": "djrHVE_XBnnz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# we use a `DataLoader` to feed the data in small batches.\n",
        "# This is more memory-efficient and often helps the model train better.\n",
        "\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "\n",
        "train_dataset = TensorDataset(X_train, y_train)\n",
        "test_dataset = TensorDataset(X_test, y_test)\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "test_loader = DataLoader(dataset=test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "data_iter = iter(train_loader)\n",
        "first_batch_features, first_batch_labels = next(data_iter)\n",
        "print(f\"\\nShape of one batch of features: {first_batch_features.shape}\")\n",
        "print(f\"Shape of one batch of labels: {first_batch_labels.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YHtByBDxjkDI",
        "outputId": "c1e85b4a-cfd0-4468-8aa9-d0b05b5a8dd9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Shape of one batch of features: torch.Size([32, 2])\n",
            "Shape of one batch of labels: torch.Size([32, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Model Definition"
      ],
      "metadata": {
        "id": "Itp3PlHsC_jQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class SimpleClassifier(nn.Module):\n",
        "    def __init__(self, input_features, hidden_units):\n",
        "        super().__init__()\n",
        "        self.linear1 = nn.Linear(in_features=input_features, out_features=hidden_units) # fully-connected layer or dense layer\n",
        "        self.linear2 = nn.Linear(in_features=hidden_units, out_features=1)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.linear1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.linear2(x)\n",
        "        x = self.sigmoid(x)\n",
        "        return x\n",
        "\n"
      ],
      "metadata": {
        "id": "I2oRaouidKQg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = SimpleClassifier(input_features=N_FEATURES, hidden_units=10)\n",
        "print(\"\\nModel Architecture:\")\n",
        "print(model)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FTRDaRuQN5WD",
        "outputId": "534186f8-06f7-407b-e3ab-fac17e1dba69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Model Architecture:\n",
            "SimpleClassifier(\n",
            "  (linear1): Linear(in_features=2, out_features=10, bias=True)\n",
            "  (linear2): Linear(in_features=10, out_features=1, bias=True)\n",
            "  (relu): ReLU()\n",
            "  (sigmoid): Sigmoid()\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fttPr9HBN7DT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "----\n",
        "\n",
        "#### ***Loss Function***\n",
        "\n",
        "The loss function is a mathematical process that quantifies the error margin between a model's prediction and the actual target value.\n",
        "\n",
        "A loss function applies to a *single training example* and is part of the overall model's learning process that provides the signal by which the model's learning algorithm updates the weights and parameters.\n",
        "\n",
        "Types:\n",
        "\n",
        "- Mean Absolute Error (MAE) / L1 Loss [*Regression*]\n",
        "- Mean Square Error (MSE) / L2 Loss [*Regression*]\n",
        "- Binary Cross-Entropy Loss / Log Loss [*Classification*]\n",
        "- Categorical Cross-Entropy Loss [*Classification*]\n",
        "\n",
        "\n",
        "#### ***Cost Function***\n",
        "\n",
        "The cost function, sometimes called the objective function, is an average of the loss function of an entire training set containing several training examples. The cost function quantifies the model's performance on the whole training dataset.\n",
        "\n",
        "----\n",
        "\n",
        "#***Backward Pass (Backpropagation):***\n",
        "\n",
        "<p>The calculated loss is propagated backward through the network, starting from the output layer and moving towards the input layer. Using the chain rule of calculus, the algorithm calculates the gradient of the loss function with respect to each weight and bias in the network. </p>\n",
        "\n",
        "\n",
        "# ***Optimization***\n",
        "Optimization is the process of adjusting a model's parameters (weights and biases) to minimize a loss function.\n",
        "\n",
        "---\n",
        "#### ***Gradient∇L(θ)***\n",
        "The gradient of the loss function, denoted as ∇L(θ), is a vector of partial derivatives. Each element in this vector is the partial derivative of the loss function L with respect to one specific parameter θᵢ:\n",
        "\n",
        "$∇L(θ) = [ ∂L/∂θ₁, ∂L/∂θ₂, ∂L/∂θ₃, ... , ∂L/∂θₙ ]$\n",
        "\n",
        "The gradient vector ∇L(θ) has two fundamental properties:\n",
        "- Direction: It points in the direction of the steepest ascent of the loss function in the multi-dimensional parameter space.\n",
        "- Magnitude: Its length or norm, ||∇L(θ)||, represents the steepness of that ascent.\n",
        "----\n",
        "#### ***Learning Rate (α)***\n",
        "This is a hyperparameter that determines the size of the step we take in the opposite direction of the gradient.\n",
        "- Too small: Training will be very slow.\n",
        "- Too large: You might overshoot the minimum and bounce around, failing to converge.\n",
        "----\n",
        "#### ***Gradient Descent***\n",
        "The fundamental update rule for Gradient Descent is:\n",
        "\n",
        " *new_weights = old_weights - learning_rate * gradient*\n",
        "\n",
        "\n",
        "#### ***Variants of Gradient Descent***\n",
        "\n",
        "- Batch Gradient Descent (BGD): Calculates the gradient using the entire training dataset for one update.\n",
        "- Stochastic Gradient Descent (SGD): Calculates the gradient using a single, randomly chosen data point for one update.\n",
        "- Mini-Batch Gradient Descent: The compromise and the de facto standard. It calculates the gradient using a small batch of data (e.g., 32, 64, 256 samples).\n",
        "\n",
        "#### ***Momentum-Based Methods (Adding \"Memory\")***\n",
        "\n",
        "- SGD with Momentum\n",
        "- Adaptive Learning Rate Methods (Per-Parameter Tuning)\n",
        "- Adagrad (Adaptive Gradient Algorithm):\n",
        "- RMSprop (Root Mean Square Propagation):\n",
        "- Adam (Adaptive Moment Estimation)"
      ],
      "metadata": {
        "id": "oDDMgtCLEZOH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Training Process"
      ],
      "metadata": {
        "id": "53va6ExnNrio"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "loss_function = nn.BCELoss()  # Binary Cross-Entropy Loss for binary classification.\n",
        "learning_rate = 0.01\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "epochs = 5\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "\n",
        "    for batch_idx, (batch_features, batch_labels) in enumerate(train_loader):\n",
        "        # Forward pass\n",
        "        y_pred = model(batch_features)\n",
        "\n",
        "        # Calculate loss for this batch.\n",
        "        loss = loss_function(y_pred, batch_labels)\n",
        "\n",
        "        # Clear gradients from the previous batch.\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Backward pass (Backpropagation)\n",
        "        loss.backward()\n",
        "\n",
        "        # Update the model's weights and biases.\n",
        "        optimizer.step()\n",
        "\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        full_train_preds = model(X_train)\n",
        "        epoch_loss = loss_function(full_train_preds, y_train)\n",
        "        print(f'Epoch {epoch+1}/{epochs} | Loss: {epoch_loss.item():.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rfMYTcmvEAvA",
        "outputId": "948bb7c3-a2ef-4db4-f3a1-be9047bb2815"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5 | Loss: 0.1657\n",
            "Epoch 2/5 | Loss: 0.0401\n",
            "Epoch 3/5 | Loss: 0.0231\n",
            "Epoch 4/5 | Loss: 0.0180\n",
            "Epoch 5/5 | Loss: 0.0155\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Evaluate Model"
      ],
      "metadata": {
        "id": "Tn3hSEpfPdIl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "model.eval()  # Set model to evaluation mode\n",
        "\n",
        "total_correct = 0\n",
        "total_samples_in_test = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch_features, batch_labels in test_loader:\n",
        "        test_preds = model(batch_features)\n",
        "        test_preds_labels = test_preds.round()\n",
        "\n",
        "        total_correct += (test_preds_labels == batch_labels).sum().item()\n",
        "        total_samples_in_test += batch_labels.size(0)\n",
        "\n",
        "accuracy = (total_correct / total_samples_in_test) * 100\n",
        "print(f\"\\nModel Accuracy on Test Set: {accuracy:.2f}%\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_XCoCGxNPJqP",
        "outputId": "980c08bf-0b52-461d-f164-e835435a50cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Model Accuracy on Test Set: 100.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Save Model"
      ],
      "metadata": {
        "id": "8b5wBeAhP1n_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_SAVE_PATH = 'simple_classifier.pth'\n",
        "torch.save(model.state_dict(), MODEL_SAVE_PATH)"
      ],
      "metadata": {
        "id": "UeI6nHqtdeOl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Load Model\n",
        "\n",
        ".pth saves the weights but does not save model architecture. Model architecture must be known beforehand to load weights in pytorch."
      ],
      "metadata": {
        "id": "SowAPWF4wXZI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Create a new instance of the model. It must have the same architecture.\n",
        "loaded_model = SimpleClassifier(input_features=N_FEATURES, hidden_units=10)\n",
        "print(\"Created a new, untrained model instance:\")\n",
        "print(loaded_model)"
      ],
      "metadata": {
        "id": "OQZ_ZBesQYaO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88076c74-c957-4fb0-c979-320559e7accd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created a new, untrained model instance:\n",
            "SimpleClassifier(\n",
            "  (linear1): Linear(in_features=2, out_features=10, bias=True)\n",
            "  (linear2): Linear(in_features=10, out_features=1, bias=True)\n",
            "  (relu): ReLU()\n",
            "  (sigmoid): Sigmoid()\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_model.load_state_dict(torch.load(MODEL_SAVE_PATH))\n"
      ],
      "metadata": {
        "id": "JYMiuKp5xBjO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ec1404c-0724-40a8-a774-797ee48a43b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Inference"
      ],
      "metadata": {
        "id": "DmweUvQrjFP6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "point_1 = torch.tensor([[-2.5, 3.0]])\n",
        "point_2 = torch.tensor([[6.8, -2.5]])\n",
        "\n",
        "\n",
        "with torch.no_grad():\n",
        "    pred_1 = loaded_model(point_1)\n",
        "    pred_2 = loaded_model(point_2)\n",
        "\n",
        "print(f\"Point 1 prediction: probability: {pred_1.item()} class: {int(pred_1.round().item())} \")\n",
        "print(f\"Point 2 prediction: probability: {pred_2.item()} class: {int(pred_2.round().item())} \")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ln37lj23jGzF",
        "outputId": "41d5eb86-d9b7-43fe-c4ba-f0acb80af02a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Point 1 prediction: probability: 0.2791285812854767 class: 0 \n",
            "Point 2 prediction: probability: 0.9995813965797424 class: 1 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rdPEgr2NjPpt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}